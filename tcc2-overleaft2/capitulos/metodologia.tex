\chapter{Metodologia}\label{cap:metodologia}
Segundo \cite{metodologia} metodologia vem do grego (\textit{methodos + logia}) ou "estudo do método", e método do grego (\textit{methodos}) (\textit{methà + odon}) quer dizer "o caminho para chegar", logo metodologia é o estudo de um conjunto de etapas dispostas em ordem para o estudo de uma determinada ciência e para alcançar um objetivo cientifico.

Neste capitulo e etapa do estudo serão explanadas as simulações que foram realizadas para chegar a uma conclusão sobre o funcionamento do protótipo.

Foi escolhido que os testes e simulação para validar o protótipo seria feito em módulos delimitados em funções especificas do protótipo, isso porque devido a algumas especificações como; tempo, custo verificou-se que não seria possível realizar um teste total do protótipo. Porem é devidamente valido e viável realizar testes modulares provando que a maior parte dos resultados esperados funciona. 

O funcionamento total seria por exemplo um teste de campo utilizando um vant real em um ambiente real enfrentando condições reais de temperatura, pressão, vento, luminosidade entre várias outras condições adversas que poderiam afetar o funcionamento. Porem depois de toda a pesquisa descobriu-se que testes de funcionamento que envolvam robótica ou mais especificamente um vant, são realizados primeiramente com simulações utilizando softwares e ferramentas desenvolvidos para esse fim, logo optou-se por validar o protótipo utilizando-se estas ferramentas. Devido a alguns objetivos que especificam a utilização de um computador complementar (Raspberry Pi) que sera acoplado ao vant e sera responsável pela parte de visão computacional devido ao seu baixo peso e pequeno tamanho, foi feito um \textit{benchmark} da execução do software de visão computacional comparando os resultados com o do computador utilizado para rodar os simuladores. 

De maneira a auxiliar na compreensão de como funcionara o sistema a ilustração \ref{fig:simul} representa a maneira como uma simulação real é projetada para o sistema de simulação abstrato, perceba que existe uma divisão entre cada ferramenta. Iniciando de cima para baixo nos temos:

\begin{itemize}
	\item O computador complementar (Raspberry Pi) que comportou a ferramenta de programação para VANTs Drokit é abstraída pelo próprio Dronekit API que funcionara juntamente com o software de visão computacional.
	\item O ambiente físico, gravidade, vento, terreno e luminosidade no caso o local aonde o VANT seria pilotado, e abstraído pelo software Gazebo. 
	\item O equipamento de voo quadricóptero é simulado pelo simulador de VANTs SITL que vem embutido no firmware Ardupilot.
	\item A controladora de voo Pixhawk que executa o firmware Ardupilot é simulado pelo próprio, que ja possui embutido um sistema que possibilita testes e simulações através de software.  
\end{itemize} 


\begin{figure}[H]
	\centering
	\caption{Simulação real para abstrata}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/simualacao.pdf_tex}
	\legend{Fonte: a autor.}
	\label{fig:simul}
\end{figure}



\section{Métodos}

Para uma melhor compreensão do funcionamento do sistema foram desenvolvidos diagramas, fluxogramas e gráficos que explicam modularmente cada processo. Simulações com software demonstraram o funcionamento integrado de alguns desses módulos. 

Uma bechmark de hardware também sera realizado como comparação e validação do protótipo.

\comments{Os módulos foram subdivididos, um deles sera o de visão computacional que validara o reconhecimento facial, esse modulo vai validar as funções de distinção entre um humano inserido no banco de busca e outros que não foram, numero de falsos positivos detectados.}

\section{Componentes Físicos}

Os componentes físicos são o computador utilizado nas simulações, computador complementar (Raspberry Pi)e os dispositivos de captura de imagem utilizado nos testes.

\subsection{Computador Utilizado nas Simulações}
Devido ser necessário executar simultaneamente varias ferramentas de simulação que na sua maioria se utilizam de interfaces gráficas que necessitam de renderização em tempo real, e com um sistema de visão computacional que necessita de uma GPU e boa quantidade de memoria RAM para conseguir executar sua tarefa de reconhecimento facial, foi preciso um computador com hardware de tecnologia de vanguarda.

\begin{itemize}
	\item Especificações do Computador:
	\begin{itemize}
		\item Processador:
		\begin{itemize}
			\item Intel Core i7 8700
			\item 6 núcleos de processamento
			\item 12 threads
			\item 3.20GHz de frequência base
			\item 4.60GHz de frequência máxima
			\item 12MB de memória cache
			\begin{itemize}
				\item L1 (Data) cache 6x32 KBytes
				\item L1 (Instruction) cache 6x32 KBytes
				\item L2 cache 6x256 KBytes
				\item L3 cache 12 MBytes 
			\end{itemize}
		\end{itemize}
	\end{itemize}

	\begin{itemize}
		\item Placa de Video:
		\begin{itemize}
			\item NVIDIA GFORCE RTX2070
			\item 2304 NVIDIA CUDA Cores 
			\item 1620 MHz de clock máximo
			\item 1410 MHz de clock base
			\item 8GB de memoria GDDR6
			\item Interface de memoria de 256bit
			\item Taxa de transferencial 448GB/s 
		\end{itemize}
	\end{itemize}

	\begin{itemize}
		\item Memória RAM:
		\begin{itemize}
			\item 16GB de capacidade
			\item Taxa de transferência 3200Mb/s 
			\item Tecnologia DDR4
		\end{itemize}
	\end{itemize}

	\begin{itemize}
		\item Armazenamento:
		\begin{itemize}
			\item 1TB SSD
			\item Taxa de leitura gravação 500MB/s e 450MB/s
			\item Interface SATA 3
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsection{Computador Complementar}

Devido ao fato da pesquisa propor um vant que acople um computador que comportaria o software de visão computacional, foi estipulado que este seria um Raspberry Pi, pelo seu reduzido tamanho e peso, Foi feita uma implementação do sistema de reconhecimento facial que foi utilizado na simulação, com o Raspberry Pi para provar seu funcionamento em uma possível simulação real. 

\begin{figure}[H]
	\centering	
	\caption{Raspberry Pi 3 B}
	%\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/pingpioraspberry.pdf_tex}
	\legend{Fonte: o autor com base em \cite{raspdoc}.}
	\label{fig:gpiorasp}
\end{figure}

\begin{itemize}
	\item CPU Broadcom BCM2837 de 64 bits Quad Core de 1.2GHz
	\item 1GB RAM
	\item LAN sem fio BCM43438 e Bluetooth Low Energy (BLE)
	\item 100 Base Ethernet
	\item Extensão GPIO de 40 pinos
	\item 4 portas USB 2
	\item Saída estéreo de 4 polos e porta de vídeo composto
	\item HDMI em tamanho real
	\item Porta de conexão para câmera CSI Raspberry Pi
	\item Porta de conexão para display DSI Raspberry Pi sensível ao toque
	\item Porta Micro SD para carregar seu sistema operacional e armazenar dados
	\item Fonte de alimentação Micro USB comutada atualizada até 2.5ª
\end{itemize}

\subsection{Dispositivo de Captura}

\section{Sistemas Operacionais}

Para implementar as simulações no computador foi utilizado o sistema operacional linux Mint 19, baseado no linux Ubuntu Bionic. Para implementar o sistema de reconhecimento facial no computador complementar foi utilizado o sistema operacional linux Raspbian sem interface gráfica, que também é baseado no Ubuntu Bionic.
A maioria das ferramentas são desenvolvidas para sistemas UNIX e que se baseiam no Linux Debian e Ubuntu por isso se chegou nessa escolha.

\section{Fluxogramas dos Protótipos e Funcionamento do Sistema}

\begin{figure}[H]
	\centering	
	\caption{Diagrama de Funcionamento do Sistema}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/diagrama1.pdf_tex}
	\legend{Fonte: a autor.}
	\label{fig:pross}
\end{figure}

%---------------------------------
\subsection{Transformação do Sistema de Coordenadas do OpenCV}

Essa etapa foi fundamental para a implementação e funcionamento do protótipo, a ideia é simples foram delimitadas regiões de interesse na utilizando o OpenCV, a ilustração \ref{fig:regint} mostra todas as cinco áreas. No centro da tela se situa a região de não interesse e como o sugere o nome dentro desse retângulo não existe reação do sistema de estreamento, porem caso a pessoa se mova e saia de dentro o sistema detecta para qual direção esta se dirigindo. A simplicidade vem do fato de o objetivo ou a lógica principal ser sempre manter o alvo (retângulo verde criado pelo OpenCV em torno da face humana) sempre dentro da região de não interesse.  

\begin{figure}[H]
	\centering
	\caption{Regiões de Interesse}
	\input{figs/mathcha/regiaoint.tex}
	\legend{Fonte: do autor}
	\label{fig:regint}
\end{figure}

Porem a ideia das regiões de intersere não trata todas as possibilidades, como uma movimentação na diagonal, e dessa forma foi necessário desenvolver outras etapas. Uma das primeiras etapas da implementação foi modificar o sistema de coordenadas de pixels no qual o OpenCV se baseia, para tornar conveniente sua utilização no sistema que detecta em qual direção o VANT tem que se movimentar. A ilustração \ref{fig:quad1} representa como o OpenCV trabalha com coordenadas de pixels, perceba que o ponto de origem das coordenadas verticais e Horizontais se situam na parte superior esquerda, logo não é possível identificar o sentido direcional em que o ponto na cor vermelha no centro da face esta se movendo. Para fins de orientação se estipulou que as linhas de pixels na horizontal pertencem a X e os na vertical a Y, e como é possível identificar com uma ferramenta do OpenCV o centro do retângulo desenhado em torno da face através de Axy e Bxy, então se encontrou as coordenadas X e Y do ponto vermelho central.

\begin{figure}[H]
	\centering
	\caption{Sistema de Coordenadas do OpenCV}
	\input{figs/mathcha/quadrado1.tex}
	\legend{Fonte: do autor}
	\label{fig:quad1}
\end{figure}

Para que o sistema funciona-se as coordenadas X=0 e Y=0 foram transportadas para um ponto central da tela, portanto foram realizados cálculos para determinar dois eixos um na horizontal e outro na vertical e sua intersecção ou ponto médio é o epicentro do novo sistema de coordenadas. Na ilustração \ref{fig:quad2} as duas retas na cor marrom representam o novo sistema, assim foi possível equacionar um novo ponto central para o retângulo que é  desenhado em torno da face, esse novo ponto é dado como B' e ele recebe os valores calculados para fx' e fy'.   

\begin{figure}[H]
	\centering
	\caption{Conversão do Sistema de Coordenadas OpenCV para Coordenadas Cartesianas}
	\input{figs/mathcha/quadrado3.tex}
	\legend{Fonte: do autor}
	\label{fig:quad2}
\end{figure}

O objetivo de obter um sistema de coordenadas que pudesse ser utilizado para orientar o direcionamento do VANT foi alcançado e ele pode ser observado na ilustração \ref{fig:teste}, esse sistema de coordenadas é denominado de cartesiano e possui quatro quadrantes distintos e bem definidos, é o mesmo utilizado para localização geográfica na superfície terrestre. Da mesmo forma que aeronaves conseguem se orientar na superfície terrestre usando coordenadas cartesianas, também é possível guiar um VANT para chegar ao objetivo do protótipo.

Com o novo sistema de coordenadas foi possivel obter valores para X e Y com uma maior precisão (0.005m/s a 5m/s), assim como os quatro quadrantes conseguem indicar para qual direção a aeronave tem que se deslocar. Esses valores de velocidade posteriormente serão enviados para a controladora de voo do VANT. 

A interpretação das informações da ilustração \ref{fig:quad2} pode ser feita através das seguintes sintaxes matemáticas; 

\begin{itemize}
	\item Sintaxe do quadrante I:\begin{equation}\label{q1} B'\in (Quadrante\ I) \mid \left(\frac{W}{2} -Bx >0\right) \land \left(\frac{H}{2} -By >0\right)\end{equation} 
	\item Sintaxe do quadrante II:\begin{equation}\label{q2} B'\in (Quadrante\ II) \mid \left(\frac{W}{2} -Bx <0\right) \land \left(\frac{H}{2} -By >0\right)\end{equation} 
	\item Sintaxe do quadrante III:\begin{equation}\label{q3} B'\in (Quadrante\ III) \mid \left(\frac{W}{2} -Bx <0\right) \land \left(\frac{H}{2} -By <0\right)\end{equation} 
	\item Sintaxe do quadrante IV:\begin{equation}\label{q4} B'\in (Quadrante\ IV) \mid \left(\frac{W}{2} -Bx >0\right) \land \left(\frac{H}{2} -By <0\right)\end{equation} 
	\item Sintaxe quando não pertence a nenhum quadrante:\begin{equation}\label{nq} B'\notin ( Quadrante\ I\lor II\lor III\lor IV) \mid \left(\frac{W}{2} -Bx=0\right) \lor \left(\frac{H}{2} -By=0\right)\end{equation}
\end{itemize} 

\begin{figure}[H]
	\centering
	\caption{Sistema de Coordenadas Cartesianas em Visão Computacional}
	\input{figs/mathcha/quadrado2.tex}
	\legend{Fonte: do autor}
	\label{fig:teste}
\end{figure}

Para concluir essa parte a ilustração \ref{fig:conv} representa a projeção em 3D do sistema de coordenadas original que o OpenCV utiliza e como fica apos a transformação. O OpenCV possui o eixo Z (profundidade), ele é utilizado para calcular a posição em um sistema 3D ou adquirir a velocidade de deslocamento, porem essa etapa não sera abordada mas pode ser um bom tema para trabalhos futuros ou aperfeiçoamento do sistema.

\begin{figure}[htpb]
	\centering
	\caption{Projeção do Sistema de Coordenadas OpenCV para Cartesianas}
	\input{figs/mathcha/conv.tex}
	\legend{Fonte: do autor}
	\label{fig:conv}
\end{figure}

Para demonstrar como o VANT interage e interpreta os dados que recebe do sistemas de visão computacional e atua para se orientar, foram criados dois modelos de gráfico do tipo vetor gradiente, aonde o tom de cor mais forte representa o valor máximo e consequentemente o tom mais claro o mínimo valor. Foi estipulado que o valor máximo seria de $\displaystyle \eqsim 5/ms$, observando que segundo o site Ardupilot.org-docs\footnote{\url{https://ardupilot.org/copter/docs/auto-mode.html}} um VANT do tipo quadricóptero atinge de 10m/s $\displaystyle \eqsim13m/s$ no máximo, antes de se tornar incapaz de manter a altitude e a velocidade horizontal. 

O primeiro gráfico ilustrado pela figura \ref{fig:teste8} tem como objetivo interpretar como o sistema de visão computacional atua junto com o Dronekit. Se o gráfico \ref{fig:teste8} for sobreposto pela tela do OpenCV a parte aonde o gradiente é mais fraco fica no centro, ou seja, local aonde o software de visão computacional definiu como região de não interesse (não existe velocidade ou é insignificante), ja nas bordas a coloração é mais forte, isso significa que quando a pessoa que esta sendo monitorada pelo software estiver se aproximando  das bordas da interface de captura da câmera, a velocidade aumenta gradualmente, tendo como objetivo sempre manter o alvo no centro da tela, logo conforme o alvo estiver se aproximando do centro a velocidade gradualmente vai diminuindo até parar assim que chegar ao centro e estiver na região de não interesse.

As escalas nos eixos X e Y contem os possíveis valores de velocidade em m/s que podem ser enviados para o VANT, como ja foi abordada no referencial teórico é utilizado o sistema de orientação por coordenadas NED e por regra nesse sistema de coordenadas o X fica no eixo das ordenadas e Y no eixo das abcissas.

No gráfico \ref{fig:teste9} foram adicionadas duas cores para distinguir as velocidades em X e Y, os VANTs representam graficamente algumas posições dentro do sistema de coordenas com seus respectivos valores de velocidade nos vetores X e Y assim como qual direção eles toram ao receber os valores de velocidade. A cor verde representa o gradiente de velocidade no eixo X e a cor vermelha no eixo Y e igualmente como no gráfico \ref{fig:teste8} nas bordas tem sua maior intensidade de velocidade e no centro não existe ou é insignificante as forças de velocidade. Nos eixos diagonais a X e Y pontos (A,B,C,D) as cores se sobrepõem, isso significa que os valores de velocidade serão iguais ou próximos para X e Y nesse ponto.

Analisando todos os pontos no gráfico \ref{fig:teste9} aonde estão os VANTs:

\begin{itemize}
	\item VANT 1: Nesse ponto x=-0.9ms e y=1.9m/s, e de acordo com a regra \ref{q2} pertence ao quadrante II, tem direção Noroeste tendendo a se aproximar mais do eixo X por ter uma mair velocidade na componente X.
	\item VANT 2: Nesse ponto x=5ms e y=0m/s, e de acordo com a regra \ref{nq} não pertence a nenhum quadrante por ter uma das componentes de velocidade com valor nulo, porem podemos dizer que tem direção Norte de acordo com a componente x.
	\item VANT 3: Nesse ponto x=-3.95ms e y=-6.5m/s, e de acordo com a regra \ref{q3} pertence ao quadrante III, tem direção Sudoeste e tendendo a se aproximar mais do eixo Y por ter uma mair velocidade na componente Y.
	\item VANT 4: Nesse ponto x=1.5ms e y=3.8m/s, e de acordo com a regra \ref{q1} pertence ao quadrante I, tem direção Nordeste tendendo a se aproximar mais do eixo Y por ter uma mair velocidade na componente Y.
	\item VANT 5: Nesse ponto x=-3.6ms e y=3.75m/s, e de acordo com a regra \ref{q4} pertence ao quadrante IV, tem direção Sudeste e nesse caso tem diferença de valores nas componentes X e Y insignificante não tendendo a se direcionar a nenhum dos eixos.
\end{itemize}
 

\begin{figure}[htpb]
	\centering
	\caption{Gráfico que Representa o Gradiente de Velocidade}
	\input{figs/mathcha/com-amarelo.tex}
	\legend{Fonte: do autor}
	\label{fig:teste8}
\end{figure}

\begin{figure}[H]
	\centering
	\caption{Gráfico que Representa o Gradiente de Velocidade para X e Y}
	\input{figs/mathcha/com-vermelho-verde.tex}
	\legend{Fonte: do autor}
	\label{fig:teste9}
\end{figure}

%\begin{python_}
%def send_local_ned_velocity(vehicle, vx, vy, vz):
%	"""
%	Move vehicle in direction based on specified velocity vectors.
%	"""
%	msg = vehicle.message_factory.set_position_target_local_ned_encode(
%		0,       # time_boot_ms (not used)
%		0, 0,    # target system, target component
%		mavutil.mavlink.MAV_FRAME_BODY_OFFSET_NED, # frame
%		0b0000111111000111, # type_mask (only speeds enabled)
%		0, 0, 0, # x, y, z positions (not used)
%		vx, vy, vz, # x, y, z velocity in m/s
%		0, 0, 0, # x, y, z acceleration (not supported yet, ignored in GCS_Mavlink)
%		0, 0)    # yaw, yaw_rate (not supported yet, ignored in GCS_Mavlink)
%	
%	# send command to vehicle on 1 Hz cycle
%	vehicle.send_mavlink(msg)
%	vehicle.flush()
%\end{python_}

\begin{figure}[htpb]
	\centering
	\caption{Conexão MAVLink da Raspberry Pi com Pixhawk}
	\fontsize{9pt}{12pt}\selectfont
	\color{black}
	\def\svgwidth{15cm}
	\input{figs/svg/pixhawk-raspberry.pdf_tex}
	\legend{Fonte: Ardupilot Documents}
	\label{fig:mavlink}
\end{figure}



\section{Simulações com Software}

\section{Simulações com Hardware}





%\draw (467.32,239.58) node [xslant=-0.33] {
%	\def\svgwidth{0.8cm}
%	\input{{figs/svg/drone3.pdf_tex}}};
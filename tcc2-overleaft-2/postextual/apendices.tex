% ----------------------------------------------------------
% Apêndices
% ----------------------------------------------------------

% ---
% Inicia os apêndices
% ---
\begin{apendicesenv}

% Imprime uma página indicando o início dos apêndices
\partapendices

% ----------------------------------------------------------
\chapter{Código Fonte da Visão Computacional}
% ----------------------------------------------------------

\begin{python_}
# USAGE
# python recognize_faces_video.py --encodings encodings.pickle

# importação das bibliotecas
# import the necessary packages
from collections import deque
from imutils.video import VideoStream
from imutils.face_utils import rect_to_bb
from decimal import Decimal
from dronekit import connect,VehicleMode,LocationGlobalRelative,APIException
from functionsControlDrone import connectMyCopter, 
arm_and_takeoff, send_local_ned_velocity,send_global_ned_velocity
import face_recognition
import argparse
import imutils
import pickle
import time
import numpy as np
import cv2


# construção dos argumentos passados
# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-e", "--encodings", default="encodings.pickle",
help="path to serialized db of facial encodings")
ap.add_argument("-o", "--output", type=str,	
help="path to output video")
ap.add_argument("-y", "--display", type=int, default=1,	
help="whether or not to display output frame to screen")
ap.add_argument("-d", "--detection-method", type=str, default="cnn", 
help="face detection model to use: either (hog0 or (cnn)")
ap.add_argument("-b", "--buffer", type=int, default=64,	
help="max buffer size")
ap.add_argument('--connect')	
args = vars(ap.parse_args())

# conectar o VANT (MAVLink)
# connect the UAV (MAVLink)
vehicle = connectMyCopter()

#def vision():
# load the known faces and embeddings
# carrega o arquivo de faces conhecidas pré-treinada
print("[INFO] loading encodings...")
data = pickle.loads(open(args["encodings"], "rb").read())

pts = deque(maxlen=args["buffer"])
counter = 0
(dX, dY) = (0, 0)
direction = ""
auxX=""
auxY=""
auxVelX=""
auxVelY=""
VELMAX = 5


# allow the câmera sensor to warm up
# aguarda a câmera inicializar
print("[INFO] starting video stream...")
vs = VideoStream(src=0).start()
writer = None
time.sleep(2.0)

# loop sobre quadros do fluxo de arquivos de vídeo
# loop over frames from the video file stream
while True:

	# pegue o quadro do fluxo de vídeo encadeado
	# grab the frame from the threaded video stream
	frame = vs.read()
	
	# converta o quadro de entrada de BGR para RGB e redimensione-o para ter
	# uma largura de 750px (para acelerar o processamento)
	# convert the input frame from BGR to RGB then resize it to have
	# a width of 750px (to speedup processing)
	rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
	rgb = imutils.resize(frame, width=750)
	r = frame.shape[1] / float(rgb.shape[1])
	
	# calcula varias coordenas de posicionamento x,y em pixels na tela do opencv
	# calculates various x, y positioning coordinates in pixels on the opencv screen
	(height, width) = frame.shape[:2]
	startX = int(height-height)
	startY = int(width-width)
	centerScreenX = int(width/2)
	centerScreenY = int(height/2)
	
	# converte em string
	# max_w_str = str(width)
	# max_h_str = str(height) 
	
	#cv2.circle(frame,(width,height),10, (0,21,255),-2)
	#cv2.putText(frame, "dx: {}, dy: {}".format(max_w_str, max_h_str),
	#(frame.shape[0]+40, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,0.40, 
	#(0,21,255), 1)
	
	cv2.circle(frame,(centerScreenX,centerScreenY),4, (0,21,255),-2)
	
	# detecta as coordenadas (x, y) das caixas delimitadoras
	# correspondente a cada face no quadro de entrada e depois calcule
	# os tratamentos faciais para cada rosto
	# detect the (x, y)-coordinates of the bounding boxes
	# corresponding to each face in the input frame, then compute
	# the facial embeddings for each face
	boxes = face_recognition.face_locations(rgb, model=args["detection_method"])
	encodings = face_recognition.face_encodings(rgb, boxes)
	center = None
	names = []	
	
	cv2.line(frame,(centerScreenX,0),(centerScreenX,480), (255,255,255),2) 
	cv2.line(frame,(0,centerScreenY),(640,centerScreenY), (255,255,255),2) 
	
	# loop sobre os revestimentos faciais  
	# loop over the facial embeddings
	for encoding in encodings:	
	
		# tente combinar cada rosto na imagem de entrada com os nossos conhecidos
		# attempt to match each face in the input image to our known
		# encodings
		matches = face_recognition.compare_faces(data["encodings"],
		encoding)
		name = "Unknown"
		
		# verifique se encontramos uma correspondência
		# check to see if we have found a match
		if True in matches:
		
			# encontre os índices de todas as faces correspondentes e inicialize um
			# dictionary para contar o número total de vezes que cada face
			# foi correspondido
			# find the indexes of all matched faces then initialize a
			# dictionary to count the total number of times each face
			# was matched
			matchedIdxs = [i for (i, b) in enumerate(matches) if b]
			counts = {}
			
			# faz um loop sobre os índices correspondentes e mantém uma contagem para
			# cada rosto reconhecido
			# loop over the matched indexes and maintain a count for
			# each recognized face face
			for i in matchedIdxs:
				name = data["names"][i]
				counts[name] = counts.get(name, 0) + 1
			
			# determinar a face reconhecida com o maior número
			# numero de votos (nota: no caso de um empate improvável em Python
			# seleciona a primeira entrada no dicionário)
			# determine the recognized face with the largest number
			# of votes (note: in the event of an unlikely tie Python
			# will select first entry in the dictionary)
			name = max(counts, key=counts.get)
		
		# atualiza a lista de nomes
		# update the list of names
		names.append(name)
	
	# passe pelas faces reconhecidas
	# loop over the recognized faces
	for ((top, right, bottom, left), name) in zip(boxes, names):
	
		# redimensionar as coordenadas do rosto
		# rescale the face coordinates
		top = int(top * r)
		right = int(right * r)
		bottom = int(bottom * r)
		left = int(left * r)
		
		topS = str(top)
		rightS = str(right)
		bottomS = str(bottom)
		leftS = str(left)
		
		# Pontos X e Y do centro do retângulo da face
		# X and Y points in the center of the face rectangle
		cx = int((left + right)/2.0)
		cy = int((top + bottom)/2.0)
		center = (cx, cy)
		cx_str = str(cx)
		cy_str = str(cy)
		
		# desenha o retângulo, nome do rosto, centro do quadro
		# draw the predicted face name on the image
		cv2.rectangle(frame, (left, top), (right, bottom),
		(0, 255, 0), 2)
		y = top - 15 if top - 15 > 15 else top + 15
		cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,
		0.75, (0, 255, 0), 2)
		cv2.circle(frame,(cx,cy),4, (255),-2)
		cv2.putText(frame, "dx: {}, dy: {}".format(cx_str, cy_str),
		(400, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,0.40, (0, 255, 0), 1)
		cv2.arrowedLine(frame,(centerScreenX,centerScreenY),(cx,cy), 
		(255, 255, 255),1, 8, 0, 0.1)
		pts.appendleft(center)
		x1=1
		y1=1
		
		
		# determina a região (retângulo) de não interesse  
		# determines the region (rectangle) of no interest
		l=int((cx-left)*1.025) #delta widht
		a=int((cy-top)*1.025) #delta height
		PaX = int(centerScreenX-a)
		PaY = int(centerScreenY-l)
		PbX = int(centerScreenX+a)
		PbY = int(centerScreenY+l)
		
		# desenha as regiões de interesse	
		# draw the regions of interest
		cv2.rectangle(frame, (PaX,PaY), (PbX,PbY), (211,211,211), 2)
		cv2.line(frame,(startX,PaY),(PaX,PaY), (0,128,255),1) #laranja orange
		cv2.line(frame,(startX,PbY),(PaX,PbY), (0,128,255),1) #laranja orange
		cv2.line(frame,(PaX,height),(PaX,PbY), (255),1) #azul blue
		cv2.line(frame,(PbX,height),(PbX,PbY), (255),1) #azul blue
		cv2.line(frame,(PbX,PbY),(width,PbY), (20,255,57),1) #verde green
		cv2.line(frame,(PbX,PaY),(width,PaY), (20,255,57),1) #verde green
		cv2.line(frame,(PaX,PaY),(PaX,startY), (0,0,255),1) #vermelho red
		cv2.line(frame,(PbX,PaY),(PbX,startY), (0,0,255),1) #vermelho red
		
		# valor da componente de velocidade
		# speed component value
		COMPVX=Decimal(VELMAX/centerScreenY)
		COMPVY=Decimal(VELMAX/centerScreenX)
		COMPV=Decimal((COMPVX+COMPVY)/2)
		
		# verifica em qual região de interesse a face esta,
		# calcula as velocidades
		# envia a informação para o VANT
		# check in which region of interest the face is
		# calculates speeds
		# sends the information to the UAV
		if cx in range(PaX,PbX) and cy in range(startY,PaY):
			print("NORTE")
			direction = "NORTE"
			auxX = int(centerScreenY-cy)
			auxVelY = 0
			auxVelX = round(Decimal(auxX*COMPV),4)
			print(auxVelX)
			send_local_ned_velocity(vehicle, auxVelX , 0, 0)
		elif cx in range(PaX,PbX) and cy in range(PbY,height):
			print("SUL")
			direction = "SUL"
			auxX = int(centerScreenY-cy)
			auxVelY = 0
			auxVelX = round(Decimal(auxX*COMPV),4)
			print(auxVelX)
			send_local_ned_velocity(vehicle, auxVelX , 0, 0)
		elif cx in range(PbX,width) and cy in range(PaY,PbY):
			print("LESTE")
			direction = "LESTE"
			auxVelX = 0
			auxY = int(cx-centerScreenX)
			auxVelY = round(Decimal(auxY*COMPVY),4)	
			print(auxVelY)
			send_local_ned_velocity(vehicle, 0 , auxVelY, 0)
		elif cx in range(startX,PaX) and cy in range(PaY,PbY):
			print("OESTE")
			direction = "OESTE"	
			auxVelX = 0
			auxY = int(cx-centerScreenX)
			auxVelY = round(Decimal(auxY*COMPVY),4)
			print(auxVelY)
			send_local_ned_velocity(vehicle, 0 , auxVelY, 0)
		elif cx in range(PbX,width) and cy in range(startY,PaY):
			print("NORDESTE")
			direction = "NORDESTE"
			if cx >= centerScreenX and cy <= centerScreenY:
				auxY = int(cx-centerScreenX)
				auxX = int(centerScreenY-cy)
				auxVelX = round(Decimal(auxX*COMPV),4)
				auxVelY = round(Decimal(auxY*COMPV),4)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
		elif cx in range(startX,PaX) and cy in range(startY,PaY):
			print("NOROESTE")
			direction = "NOROESTE"
			if cx <= centerScreenX and cy <= centerScreenY:
				auxY = int(cx-centerScreenX)
				auxX = int(centerScreenY-cy)
				auxVelX = round(Decimal(auxX*COMPV),4)
				auxVelY = round(Decimal(auxY*COMPV),4)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
		elif cx in range(startX,PaX) and cy in range(PbY,height):
			print("SUDOESTE")
			direction = "SUDOESTE"
			if cx <= centerScreenX and cy >= centerScreenY:
				auxY = int(cx-centerScreenX)
				auxX = int(centerScreenY-cy)
				auxVelX = round(Decimal(auxX*COMPV),4)
				auxVelY = round(Decimal(auxY*COMPV),4)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
		elif cx in range(PbX,width) and cy in range(PbY,height):
			print("SUDESTE")
			direction = "SUDESTE"
			if cx >= centerScreenX and cy >= centerScreenY:
				auxY = int(cx-centerScreenX)
				auxX = int(centerScreenY-cy)
				auxVelX = round(Decimal(auxX*COMPV),4)
				auxVelY = round(Decimal(auxY*COMPV),4)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
				send_local_ned_velocity(vehicle, auxVelX , auxVelY, 0)
		else:
			direction = ""
			auxX = 0
			auxY = 0
			auxVelX = 0
			auxVelY = 0
	
	# desenha os valores das componentes de velocidade e a direção
	# draws the values of the speed components and the direction
	cv2.putText(frame, direction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
	0.65, (255), 3)
	cv2.putText(frame, "Vel-X: {}, Vel-Y: {}".format(auxVelX, auxVelY),
	(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,
	0.35, (255), 1)
	counter += 1
	
	# se o gravador de vídeo for None * AND *, devemos escrever
	# o vídeo de saída em disco inicializa o gravador
	# if the video writer is None *AND* we are supposed to write
	# the output video to disk initialize the writer
	if writer is None and args["output"] is not None:
		fourcc = cv2.VideoWriter_fourcc(*"MJPG")
		writer = cv2.VideoWriter(args["output"], fourcc, 20,
		(frame.shape[1], frame.shape[0]), True)
	
	# se o gravador não for None, escreva o quadro com as
	# faces no disco
	# if the writer is not None, write the frame with recognized
	# faces t odisk
	if writer is not None:
		writer.write(frame)
	
	# verifique se devemos exibir o quadro de saída
	# na tela
	# check to see if we are supposed to display the output frame to
	# the screen
	if args["display"] > 0:
		cv2.imshow("Frame", frame)
		key = cv2.waitKey(1) & 0xFF
	
	# se a tecla `q` foi pressionada, interrompa o loop
	# if the `q` key was pressed, break from the loop
	if key == ord("q"):
		break
	
	# faça uma limpeza
	# do a bit of cleanup
	cv2.destroyAllWindows()
	vs.stop()
	
	# verifique se o ponto do gravador de vídeo precisa ser liberado
	# check to see if the video writer point needs to be released
	if writer is not None:
		writer.release()
\end{python_}

% ----------------------------------------------------------
\chapter{Código Fonte dos Controles do VANT}
% ----------------------------------------------------------

\begin{python_}
##########DEPENDENCIES#############
import dronekit
from dronekit import connect, VehicleMode,LocationGlobalRelative,APIException
import time
import socket
import math
import argparse
from pymavlink import mavutil
from click import exceptions
#########FUNCTIONS#################
vehicle = None

def connectMyCopter():

	global vehicle
	try:
	
		parser = argparse.ArgumentParser(description='commands')
		parser.add_argument('--connect')
		args = parser.parse_args()
		
		connection_string = args.connect
		
		if not connection_string:
			import dronekit_sitl
			sitl = dronekit_sitl.start_default()
			connection_string = sitl.connection_string()
		
		vehicle = connect(connection_string,wait_ready=True, timeout=5)
	
	except socket.error:
		print ('SEM SERVIDOR SITL EXISTENTE!')
	except exceptions.OSError as e:
		print ('SEM COMUNICAÇÃO SERIAL EXISTENTE!')
	except dronekit.APIException:
		print ('TEMPO DE CONEXÃO EXCEDIDO!')
	except:
		print ('ACONTEREAM OUTROS ERROS DE CONEXÃO!')
	
	return vehicle

def arm_and_takeoff(vehicle, targetHeight):
	while vehicle.is_armable!=True:
		print("Esperando o veiculo se armar")
		time.sleep(1)
	print("Veiculo armado")
	
	vehicle.mode = VehicleMode("GUIDED")
	
	while vehicle.mode!='GUIDED':
		print("Aguardando entrar em modo GUIDED")
		time.sleep(1)
	print("Veiculo em modo GUIDED")
	
	vehicle.armed = True
	while vehicle.armed==False:
		print("Esperando o veiculo se armar")
		time.sleep(1)
	print("Cuidado as hélices virtuais estão em funcionamento")
	
	vehicle.simple_takeoff(targetHeight) ##meters
	
	
	while True:
		print("Current Altitude: %d"%vehicle.location.global_relative_frame.alt, 
		targetHeight)
		
		if vehicle.location.global_relative_frame.alt>=.92*targetHeight:
		break
		time.sleep(1)
	print("Target altitude reached!!")
	return None

def send_local_ned_velocity(vehicle, vx, vy, vz):
	"""
	Move vehicle in direction based on specified velocity vectors.
	"""
	msg = vehicle.message_factory.set_position_target_local_ned_encode(
		0,       # time_boot_ms (not used)
		0, 0,    # target system, target component
		mavutil.mavlink.MAV_FRAME_BODY_OFFSET_NED, # frame
		0b0000111111000111, # type_mask (only speeds enabled)
		0, 0, 0, # x, y, z positions (not used)
		vx, vy, vz, # x, y, z velocity in m/s
		0, 0, 0, # x, y, z acceleration (not supported yet, ignored in GCS_Mavlink)
		0, 0)    # yaw, yaw_rate (not supported yet, ignored in GCS_Mavlink)
	
	# send command to vehicle on 1 Hz cycle
	print(" Airspeed: %s" % vehicle.airspeed)
	vehicle.send_mavlink(msg)
	vehicle.flush()


def send_global_ned_velocity(vehicle, vx, vy, vz):
	"""
	Move vehicle in direction based on specified velocity vectors.
	"""
	msg = vehicle.message_factory.set_position_target_local_ned_encode(
		0,       # time_boot_ms (not used)
		0, 0,    # target system, target component
		mavutil.mavlink.MAV_FRAME_LOCAL_NED, # frame
		0b0000111111000111, # type_mask (only speeds enabled)
		0, 0, 0, # x, y, z positions (not used)
		vx, vy, vz, # x, y, z velocity in m/s
		0, 0, 0, # x, y, z acceleration (not supported yet, ignored in GCS_Mavlink)
		0, 0)    # yaw, yaw_rate (not supported yet, ignored in GCS_Mavlink)
	
	# send command to vehicle on 1 Hz cycle
	vehicle.send_mavlink(msg)
	vehicle.flush()
\end{python_}

\end{apendicesenv}
% ---
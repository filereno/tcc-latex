\chapter{Metodologia}\label{cap:metodologia}
Segundo \cite{metodologia} metodologia vem do grego (\textit{methodos + logia}) ou "estudo do método", e método do grego (\textit{methodos}) (\textit{methà + odon}) quer dizer "o caminho para chegar", logo metodologia é o estudo de um conjunto de etapas dispostas em ordem para o estudo de uma determinada ciência e para alcançar um objetivo cientifico.

Neste capitulo, e etapa do estudo serão explanadas as simulações que foram realizadas para chegar a uma conclusão sobre o funcionamento do protótipo.

Foi determinado que os testes e simulação para validar o protótipo seria feito em módulos delimitados em funções especificas do protótipo, isso porque devido a algumas especificações como; tempo, custo verificou-se que não seria possível realizar um teste total do protótipo. Porem é devidamente valido e viável realizar testes modulares provando que a maior parte dos resultados esperados funciona. 

O funcionamento total seria por exemplo um teste de campo utilizando um VANT real em um ambiente real enfrentando condições reais de temperatura, pressão, vento, luminosidade entre várias outras condições adversas que poderiam afetar o funcionamento. Porem depois de toda a pesquisa descobriu-se que testes de funcionamento que envolvam robótica ou mais especificamente um VANT, são realizados primeiramente com simulações utilizando softwares e ferramentas desenvolvidos para esse fim, logo optou-se por validar o protótipo com o uso destas ferramentas. 

Devido a alguns objetivos que especificam a utilização de um computador complementar (Raspberry Pi) que sera acoplado ao VANT e sera responsável pela parte de visão computacional, foi realizada uma simulação do tipo \textit{benchmark} rodando o código fonte de visão computacional comparando os resultados com o do computador utilizado para rodar os simuladores. 

De maneira a auxiliar na compreensão de como funcionara o sistema a ilustração \ref{fig:simul} representa como a simulação real é projetada para o sistema de simulação abstrato, perceba que existe uma divisão entre cada ferramenta. Iniciando de cima para baixo nos temos:

\begin{itemize}
	\item O computador complementar (Raspberry Pi) que comportou a ferramenta de programação para VANTs Dronekit é abstraída pelo próprio Dronekit API que funcionara juntamente com o software de visão computacional.
	\item O ambiente físico, gravidade, vento, terreno e luminosidade no caso o local aonde o VANT seria pilotado, é abstraído pelo software Gazebo. 
	\item O equipamento de voo quadricóptero é simulado pelo simulador de VANTs SITL que vem embutido no firmware Ardupilot.
	\item A controladora de voo Pixhawk que executa o firmware Ardupilot é simulado pelo próprio, que ja possui embutido um sistema que possibilita testes e simulações através de software.  
\end{itemize} 


\begin{figure}[H]
	\centering
	\caption{Simulação real para abstrata}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/simualacao.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:simul}
\end{figure}

A arquitetura do sistema de simulação pode ser observado na ilustração \ref{fig:arc} ficando mais claro como os módulos dos simuladores se integram. 

\begin{figure}[H]
	\centering
	\caption{Arquitetura Básica do Sistema de Simulação}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/arcsist.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:arc}
\end{figure}

\section{Métodos}

Para uma melhor compreensão do funcionamento do sistema foram desenvolvidos diagramas, fluxogramas e gráficos que explicam modular mente cada processo. Simulações com software foram utilizadas pata testar o funcionamento integrado de alguns desses módulos. 

Uma simulação bechmark de hardware também foi realizado para comparação e validação do protótipo.

Os módulos foram subdivididos, um deles sera o de visão computacional que validara o reconhecimento facial, esse modulo vai validar as funções de distinção entre um humano inserido no banco de busca e outros que não foram, e um denominado de controla e automação que de acordo com o tema do trabalho é o mais importante por determinar toda parte de controle do VANT.
%------------------------

%------------------------
\section{Protótipo}
O protótipo consistem em um sistema que determinara se é possível utilizar visão computacional, ou mais especificamente o método de reconhecimento facial, para controlar um veiculo do tipo VANT, ou seja desenvolver um sistema de controle e automação para essa finalidade.
Primeiramente seria utilizado partes físicas de um VANT do tipo quadricóptero acompanhando uma controladora de voo (Pixhawk) com o \textit{firmware} Ardupilot, e a parte de visão computacional estaria em um computador complementar (RaspBeryy Pi), os dois seriam interligados utilizando protocolo MAVLink. Porem se optou por utilizar um conjunto de ferramentas de simulação para realizar os testes funcionais.

Essas ferramentas de simulação, simulam todo o hardware que seria utilizado no caso de simulações reais físicas. 

Como todas as ferramentas são implementas em linguagem python, a codificação do algoritmo também foi desenvolvida em python para uma melhor integração das ferramentas, módulos e bibliotecas.

Foi determinado que o sistema se divide em duas partes; visão computacional responsável pela etapa de reconhecimento facial. E o sistema de controle e automação; responsável por toda parte que implementa o sistema de controla e automação do VANT.

No diagrama \ref{fig:pross} é possível observar mas detalhadamente as duas partes aonde cada circulo representa uma etapa da logica de processo do algoritmo, e a intercessão entre os círculos representam a ação que determina a mudança de estado entre processos.

O inicio do sistema poderia ser definido de varias maneiras, porem foi determinado que ao atingir uma altitude especificada daria inicio ao sistema iniciando o módulo de reconhecimento facial, quando uma face for reconhecida o algoritmo detecta se ouve uma mudança de posição que represente um deslocamento justificável, caso seja verdadeiro o deslocamento, é identificado para qual região de interesse se deslocou, logo se o deslocamento for em direção a alguma das regiões (Norte, Sul Leste, Oeste), é enviado para o VANT a direção em que ele deve se movimentar, porem caso o deslocamento seja na diagonal, o sistema computa os valores das componentes de velocidade X e Y enviando para o VANT.   
 
\subsection{Fluxogramas dos Protótipos e Funcionamento do Sistema}
 
 Como ja foi abordado antes a ilustração \ref{fig:pross} representa o sistema em uma visão macro e como um todo dividida em dois blocos (controle e visão computacional) e dentro deles quais etapas fazem parte, assim como as ações que acarretam em mudança de etapa. E para explanarmos mais detalhadamente o funcionamento do sistema, três diagramas UML representaram em visão midi como funciona cada parte, primeiro o digrama UML \ref{fig:diasist} mostra o sistema em um todo, o \ref{fig:diagvisao} as etapas de visão computacional e o \ref{fig:diagcont} a parte de controle.


\begin{figure}[H]
	\centering	
	\caption{Diagrama de Funcionamento do Sistema}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/diagrama1.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:pross}
\end{figure}

\subsubsection{Digramas UML da Codificação e Lógica do Software}

No diagrama \ref{fig:diasist} cada elemento UML mostra a qual parte do sistema ele se adequá através da legenda dividida em cores, salmão para visão computacional e amarelo para controle. Cada elemento contem a definição da lógica que ele executa dentro do software.

A ilustração \ref{fig:diagvisao} defini as partes e funções lógicas das etapas que conferem o algoritmo de reconhecimento facial do protótipo.  

E na ilustração \ref{fig:diagcont} a definição das partes dentro do algoritmo que representam o sistema de controle do VANT. 

\begin{figure}[H]
	\centering	
	\caption{Diagrama UML Total do Sistema}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{13cm}
	\input{figs/svg/diagvisao.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:diasist}
\end{figure}

\begin{figure}[H]
	\centering	
	\caption{Diagrama UML do Sistema de Reconhecimento Facial}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{10cm}
	\input{figs/svg/diagrecfac.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:diagvisao}
\end{figure}

\begin{figure}[H]
	\centering	
	\caption{Diagrama UML do Sistema de Controle}
	\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{8cm}
	\input{figs/svg/diagcont.pdf_tex}
	\legend{Fonte: do autor.}
	\label{fig:diagcont}
\end{figure}
%---------------------------------
\subsection{Desenvolvimento do Sistema de Coordenadas Cartesiano e do Sistema de Controle}

Foi necessariíssimo desenvolver um novo sistema de coordenadas baseando-se em um sistema cartesiano. Para isso foram realizados alguns cálculos em cima do sistema de coordenas do OpenCV, para obter um protótipo de sistema do tipo cartesiano que gera-se valores para os eixos X e Y de forma balanceada 

\subsubsection{Regiões de Interesse}

Essa etapa foi fundamental para a implementação e funcionamento do protótipo, a ideia é simples foram delimitadas regiões de interesse utilizando o OpenCV, a ilustração \ref{fig:regint} mostra todas as cinco áreas. No centro da tela se situa a região de não interesse e como o nome sugere dentro dessa região ou retângulo não existe reação do sistema de estreamento, porem caso a pessoa se mova e saia de dentro o sistema detecta em qual direção esta se deslocando. A simplicidade vem do fato de o objetivo ou a lógica principal ser sempre manter o alvo (retângulo verde criado pelo OpenCV em torno da face humana) no dentro da região de não interesse.  

\begin{figure}[H]
	\centering
	\caption{Regiões de Interesse}
	\input{figs/mathcha/regiaoint.tex}
	\legend{Fonte: do autor}
	\label{fig:regint}
\end{figure}
%\begin{figure}[htpb]
%  \centering
%  \includegraphics[scale=.3]{figs/logo}
%  \caption{Breve explicação sobre a figura. Deve vir abaixo da mesma.}
%  \label{fig:nome dado a figura}
%   \legend{Fonte: do autor}
%\end{figure}
As dimensões das regiões de interesse são dinâmicas ou seja elas variam de tamanha conforme a dimensão do retângulo de detecção facial do OpenCV. Essa técnica foi determinada para tratar a distância em que a detecção facial é feita, assim se o alvo da detecção esta em uma distância maior as regiões são menores e mais perto maiores, dessa forma as reações do VANT se adequaram com a distância.

Porem a ideia das regiões de intersere não trata todas as possibilidades, como uma movimentação na diagonal, e dessa forma foi necessário desenvolver outras etapas. 

\subsubsection{Conversão do Sistema de Coordenadas OpenCV para Cartesiano}

Uma das primeiras etapas da implementação foi modificar o sistema de coordenadas de pixels no qual o OpenCV se baseia, para tornar conveniente sua utilização no sistema que detecta em qual direção o VANT tem que se movimentar. A ilustração \ref{fig:quad1} representa como o OpenCV trabalha com coordenadas de pixels, perceba que o ponto de origem das coordenadas verticais e Horizontais se situam na parte superior esquerda, logo não é possível identificar o sentido direcional em que o ponto na cor vermelha no centro da face esta se movendo. Para fins de orientação se estipulou que as linhas de pixels na horizontal pertencem a X e os na vertical a Y, e como é possível identificar com uma ferramenta do OpenCV o centro do retângulo desenhado em torno da face através de Axy e Bxy, então se encontrou as coordenadas X e Y do ponto vermelho central.

\begin{figure}[H]
	\centering
	\caption{Sistema de Coordenadas do OpenCV}
	\input{figs/mathcha/quadrado1.tex}
	\legend{Fonte: do autor}
	\label{fig:quad1}
\end{figure}

Para que o sistema funciona-se as coordenadas X=0 e Y=0 foram transportadas para um ponto central da tela, portanto foram realizados cálculos para determinar dois eixos um na horizontal e outro na vertical e sua intersecção ou ponto médio é o epicentro do novo sistema de coordenadas. Na ilustração \ref{fig:quad2} as duas retas na cor marrom representam o novo sistema, assim foi possível equacionar um novo ponto central para o retângulo que é  desenhado em torno da face, esse novo ponto é dado como B' e ele recebe os valores calculados para fx' e fy'.   

\begin{figure}[H]
	\centering
	\caption{Conversão do Sistema de Coordenadas OpenCV para Coordenadas Cartesianas}
	\input{figs/mathcha/quadrado3.tex}
	\legend{Fonte: do autor}
	\label{fig:quad2}
\end{figure}

O objetivo de obter um sistema de coordenadas que pudesse ser utilizado para orientar o direcionamento do VANT foi alcançado e ele pode ser observado na ilustração \ref{fig:teste}, esse sistema de coordenadas é denominado de cartesiano e possui quatro quadrantes distintos e bem definidos, é o mesmo utilizado para localização geográfica na superfície terrestre. Da mesmo forma que aeronaves conseguem se orientar na superfície terrestre usando coordenadas cartesianas, também é possível guiar um VANT para chegar ao objetivo do protótipo.

Com o novo sistema de coordenadas foi possivel obter valores para X e Y com uma maior precisão (0.005m/s a 5m/s), assim como os quatro quadrantes conseguem indicar para qual direção a aeronave tem que se deslocar. Esses valores de velocidade posteriormente serão enviados para a controladora de voo do VANT. 

A interpretação das informações da ilustração \ref{fig:quad2} pode ser feita através das seguintes sintaxes matemáticas; 

\begin{itemize}
	\item Sintaxe do quadrante I:\begin{equation}\label{q1} B'\in (Quadrante\ I) \mid \left(Bx - \frac{W}{2} >0\right) \land \left(\frac{H}{2} - By >0\right)\end{equation} 
	\item Sintaxe do quadrante II:\begin{equation}\label{q2} B'\in (Quadrante\ II) \mid \left(Bx - \frac{W}{2} <0\right) \land \left(\frac{H}{2} - By >0\right)\end{equation} 
	\item Sintaxe do quadrante III:\begin{equation}\label{q3} B'\in (Quadrante\ III) \mid \left(Bx - \frac{W}{2} <0\right) \land \left(\frac{H}{2} - By <0\right)\end{equation} 
	\item Sintaxe do quadrante IV:\begin{equation}\label{q4} B'\in (Quadrante\ IV) \mid \left(Bx - \frac{W}{2} >0\right) \land \left(\frac{H}{2} - By <0\right)\end{equation} 
	\item Sintaxe quando não pertence a nenhum quadrante:\begin{equation}\label{nq} B'\notin ( Quadrante\ I\lor II\lor III\lor IV) \mid \left(Bx - \frac{W}{2}=0\right) \lor \left(\frac{H}{2} - By =0\right)\end{equation}
\end{itemize} 

\begin{figure}[H]
	\centering
	\caption{Sistema de Coordenadas Cartesianas em Visão Computacional}
	\input{figs/mathcha/quadrado2.tex}
	\legend{Fonte: do autor}
	\label{fig:teste}
\end{figure}

Para concluir essa parte a ilustração \ref{fig:conv} representa a projeção em 3D do sistema de coordenadas original que o OpenCV utiliza e como fica apos a transformação. O OpenCV possui o eixo Z (profundidade), ele é utilizado para calcular a posição em um sistema 3D ou adquirir a velocidade de deslocamento, porem essa etapa não sera abordada mas pode ser um bom tema para trabalhos futuros ou aperfeiçoamento do sistema.

\begin{figure}[H]
	\centering
	\caption{Projeção do Sistema de Coordenadas OpenCV para Cartesianas}
	\input{figs/mathcha/conv.tex}
	\legend{Fonte: do autor}
	\label{fig:conv}
\end{figure}

\subsubsection{Movimentação do VANT}

Para demonstrar como o VANT interage e interpreta os dados que recebe do sistemas de visão computacional e atua para se orientar, foram criados dois modelos de gráfico do tipo vetor gradiente, aonde o tom de cor mais forte representa o valor máximo e consequentemente o tom mais claro o mínimo valor. Foi estipulado que o valor máximo seria de $\displaystyle \eqsim 5/ms$, observando que segundo o site Ardupilot.org-docs\footnote{\url{https://ardupilot.org/copter/docs/auto-mode.html}} um VANT do tipo quadricóptero atinge de 10m/s $\displaystyle \eqsim13m/s$ no máximo, antes de se tornar incapaz de manter a altitude e a velocidade horizontal. 

O primeiro gráfico ilustrado pela figura \ref{fig:teste8} tem como objetivo interpretar como o sistema de visão computacional atua junto com o Dronekit. Se o gráfico \ref{fig:teste8} for sobreposto pela tela do OpenCV a parte aonde o gradiente é mais fraco fica no centro, ou seja, local aonde o software de visão computacional definiu como região de não interesse (não existe velocidade ou é insignificante), ja nas bordas a coloração é mais forte, isso significa que quando a pessoa que esta sendo monitorada pelo software estiver se aproximando  das bordas da interface de captura da câmera, a velocidade aumenta gradualmente, tendo como objetivo sempre manter o alvo no centro da tela, logo conforme o alvo estiver se aproximando do centro a velocidade gradualmente vai diminuindo até parar assim que chegar ao centro e estiver na região de não interesse.

As escalas nos eixos X e Y contem os possíveis valores de velocidade em m/s que podem ser enviados para o VANT, como ja foi abordada no referencial teórico é utilizado o sistema de orientação por coordenadas NED e por regra nesse sistema de coordenadas o X fica no eixo das ordenadas e Y no eixo das abcissas.

No gráfico \ref{fig:teste9} foram adicionadas duas cores para distinguir as velocidades em X e Y, os VANTs representam graficamente algumas posições dentro do sistema de coordenas com seus respectivos valores de velocidade nos vetores X e Y assim como qual direção eles toram ao receber os valores de velocidade. A cor verde representa o gradiente de velocidade no eixo X e a cor vermelha no eixo Y e igualmente como no gráfico \ref{fig:teste8} nas bordas tem sua maior intensidade de velocidade e no centro não existe ou é insignificante as forças de velocidade. Nos eixos diagonais a X e Y pontos (A,B,C,D) as cores se sobrepõem, isso significa que os valores de velocidade serão iguais ou próximos para X e Y nesse ponto.

Analisando todos os pontos no gráfico \ref{fig:teste9} aonde estão os VANTs:

\begin{itemize}
	\item VANT 1: Nesse ponto x=-0.9ms e y=1.9m/s, e de acordo com a regra \ref{q2} pertence ao quadrante II, tem direção Noroeste tendendo a se aproximar mais do eixo X por ter uma mair velocidade na componente X.
	\item VANT 2: Nesse ponto x=5ms e y=0m/s, e de acordo com a regra \ref{nq} não pertence a nenhum quadrante por ter uma das componentes de velocidade com valor nulo, porem podemos dizer que tem direção Norte de acordo com a componente x.
	\item VANT 3: Nesse ponto x=-3.95ms e y=-6.5m/s, e de acordo com a regra \ref{q3} pertence ao quadrante III, tem direção Sudoeste e tendendo a se aproximar mais do eixo Y por ter uma mair velocidade na componente Y.
	\item VANT 4: Nesse ponto x=1.5ms e y=3.8m/s, e de acordo com a regra \ref{q1} pertence ao quadrante I, tem direção Nordeste tendendo a se aproximar mais do eixo Y por ter uma mair velocidade na componente Y.
	\item VANT 5: Nesse ponto x=-3.6ms e y=3.75m/s, e de acordo com a regra \ref{q4} pertence ao quadrante IV, tem direção Sudeste e nesse caso tem diferença de valores nas componentes X e Y insignificante não tendendo a se direcionar a nenhum dos eixos.
\end{itemize}
 

\begin{figure}[H]
	\centering
	\caption{Gráfico que Representa o Gradiente de Velocidade}
	\input{figs/mathcha/com-amarelo.tex}
	\legend{Fonte: do autor}
	\label{fig:teste8}
\end{figure}

\begin{figure}[H]
	\centering
	\caption{Gráfico que Representa o Gradiente de Velocidade para X e Y}
	\input{figs/mathcha/com-vermelho-verde.tex}
	\legend{Fonte: do autor}
	\label{fig:teste9}
\end{figure}

\section{Treinamento da rede Neural}

Para o sistema de visão computacional foi treinada uma rede neural do tipo CNN utilizando tecnologias da NVIDIA (CUDA, CUDNN) e as bibliotecas DLIB com \textit{face-recognition} para as chamadas de detecção facial ja implementadas nelas.

O treinamento gera um arquivo que cria um vetor contendo os dados 128-D para cada face inserida no banco de dados do método de busca, assim como foi abordado no capitulo \ref{sec:recface} tendo como exemplo a ilustração \ref{fig:ext128d}.

\section{Controles do VANT}

Para controlar o VANT foi utilizado o kit de ferramentas para controle e desenvolvimento de VANTs Dronekit juntamente do \textit{firmware} Ardupilot, nele esta contido o software SITL que é utilizado para simular o funcionamento de VANTs. Foi utilizada uma API\footnote{\url{https://ardupilot.org/dev/docs/using-gazebo-simulator-with-sitl.html}} desenvolvida para integrar o SITL do Ardupilot com o software de simulação Gazebo.
A partir dai foi possível usar as chamadas de funções do Dronekit no código fonte para enviar comandos de movimento para o VANT, também é possível interceptar mensagens de telemetria do VANT como velocidade, altura e direção. E ao integrarmos essa ferramenta com a parte desenvolvida em visão computacional obtivemos o sistema de controle de VANT.

%\section{Simulações com Software}

\section{Componentes Físicos}

Os componentes físicos são o computador utilizado nas simulações, computador complementar (Raspberry Pi)e o dispositivo de captura de imagem utilizado nos testes.

\subsection{Computador Utilizado nas Simulações}
\label{subsec:compsim}

Devido ser necessário executar simultaneamente varias ferramentas de simulação que na sua maioria se utilizam de interfaces gráficas que necessitam de renderização em tempo real, e com um sistema de visão computacional que necessita de uma GPU e boa quantidade de memoria RAM para conseguir executar sua tarefa de reconhecimento facial, foi preciso um computador com hardware de tecnologia de vanguarda.

\begin{itemize}
	\item Especificações do Computador:
	\begin{itemize}
		\item Processador:
		\begin{itemize}
			\item Intel Core i7 8700
			\item 6 núcleos de processamento
			\item 12 threads
			\item 3.20GHz de frequência base
			\item 4.60GHz de frequência máxima
			\item 12MB de memória cache
			\begin{itemize}
				\item L1 (Data) cache 6x32 KBytes
				\item L1 (Instruction) cache 6x32 KBytes
				\item L2 cache 6x256 KBytes
				\item L3 cache 12 MBytes 
			\end{itemize}
		\end{itemize}
	\end{itemize}
	
	\begin{itemize}
		\item Placa de Video:
		\begin{itemize}
			\item NVIDIA GFORCE RTX2070
			\item 2304 NVIDIA CUDA Cores 
			\item 1620 MHz de clock máximo
			\item 1410 MHz de clock base
			\item 8GB de memoria GDDR6
			\item Interface de memoria de 256bit
			\item Taxa de transferencial 448GB/s 
		\end{itemize}
	\end{itemize}
	
	\begin{itemize}
		\item Memória RAM:
		\begin{itemize}
			\item 16GB de capacidade
			\item Taxa de transferência 3200Mb/s 
			\item Tecnologia DDR4
		\end{itemize}
	\end{itemize}
	
	\begin{itemize}
		\item Armazenamento:
		\begin{itemize}
			\item 1TB SSD
			\item Taxa de leitura gravação 500MB/s e 450MB/s
			\item Interface SATA 3
		\end{itemize}
	\end{itemize}
\end{itemize}

\subsection{Computador Complementar}
\label{subsec:compcomp}

Devido ao fato da pesquisa propor um vant que acople um computador que comportaria o software de visão computacional, foi estipulado que este seria um Raspberry Pi, pelo seu reduzido tamanho e peso, Foi feita uma implementação do sistema de reconhecimento facial que foi utilizado na simulação, com o Raspberry Pi para provar seu funcionamento em uma possível simulação real. 

\begin{figure}[H]
	\centering	
	\caption{Raspberry Pi 3 B}
	%\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{15cm}
	\input{figs/svg/pingpioraspberry.pdf_tex}
	\legend{Fonte: do autor com base em \cite{raspdoc}.}
	\label{fig:gpiorasp}
\end{figure}

\begin{itemize}
	\item CPU Broadcom BCM2837 de 64 bits Quad Core de 1.2GHz
	\item 1GB RAM
	\item LAN sem fio BCM43438 e Bluetooth Low Energy (BLE)
	\item 100 Base Ethernet
	\item Extensão GPIO de 40 pinos
	\item 4 portas USB 2
	\item Saída estéreo de 4 polos e porta de vídeo composto
	\item HDMI em tamanho real
	\item Porta de conexão para câmera CSI Raspberry Pi
	\item Porta de conexão para display DSI Raspberry Pi sensível ao toque
	\item Porta Micro SD para carregar seu sistema operacional e armazenar dados
	\item Fonte de alimentação Micro USB comutada atualizada até 2.5ª
\end{itemize}

\subsection{Dispositivo de Captura}

Para os testes foi utilizado um dispositivo de captura da figura \ref{fig:cam} do tipo webcam da \textit{Microsoft} modelo life-cam HD-5000.

\begin{figure}[H]
	\centering	
	\caption{Dispositivo de Captura}
	%\fontsize{9pt}{12pt}\selectfont
	%\color{white}
	\def\svgwidth{10cm}
	\input{figs/svg/cam.pdf_tex}
	\legend{Fonte: do autor}
	\label{fig:cam}
\end{figure}

\section{Sistemas Operacionais}

Para implementar as simulações no computador foi utilizado o sistema operacional linux Mint 19, baseado no linux Ubuntu Bionic.
A maioria das ferramentas são desenvolvidas para sistemas UNIX e que se baseiam no Linux Debian e Ubuntu por isso se chegou nessa escolha.



\section{Computador Complementar vs Computador Utilizado nas Simulações (Benchmarking)}

Uma simulação \textit{banchmarking} para aferir o desempenho do algoritmo visão computacional do protótipo foi implementada, comparando os resultados entre o computador utilizado nas simulações \ref{subsec:compsim} e o computador complementar (Raspberry Pi) \ref{subsec:compcomp}.

Para o computador das simulações foi utilizada a técnica de treinamento CNN\footnote{Rede Neural Convolucional Profunda}e para o computador complementar foi utilizada a tecnica HOG  



%\draw (467.32,239.58) node [xslant=-0.33] {
%	\def\svgwidth{0.8cm}
%	\input{{figs/svg/drone3.pdf_tex}}};